{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracted information from original nifti files. \n",
    "# DeepReg throws away this information and doesn't acurately calculate mTRE\n",
    "\n",
    "case2_affine = np.array([[ 3.33370864e-01,  1.59845248e-01,  3.33878189e-01, -3.39173775e+01],\n",
    "       [-1.82626724e-01,  4.61422384e-01, -3.86130475e-02, 4.38701019e+01],\n",
    "       [-3.21150362e-01, -9.64666754e-02,  3.68540883e-01, 6.26287537e+01],\n",
    "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, 1.00000000e+00]])\n",
    "\n",
    "case21_affine = np.array([[4.00647670e-01, -1.04107566e-01,  2.77501583e-01, -3.58118629e+01],\n",
    "       [ 1.67786613e-01,  4.64567333e-01, -6.78447485e-02, -8.16707916e+01],\n",
    "       [-2.44675279e-01,  1.48105368e-01,  4.07874972e-01, -8.83094406e+00],\n",
    "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, 1.00000000e+00]])\n",
    "\n",
    "case23_affine = np.array([[  0.31273046,   0.25455737,   0.29349992, -41.70222473],\n",
    "       [ -0.28844342,   0.40450525,  -0.04210297,   2.00646901],\n",
    "       [ -0.2584393 ,  -0.14343421,   0.40214738,   4.35490799],\n",
    "       [  0.        ,   0.        ,   0.        ,   1.        ]])\n",
    "\n",
    "DeepReg_rescale = (128, 128, 128)\n",
    "\n",
    "case2_size = (128, 161, 106)\n",
    "case2_scale = np.array([case2_size[0] / DeepReg_rescale[0], \n",
    "                        case2_size[1] / DeepReg_rescale[1], \n",
    "                        case2_size[2] / DeepReg_rescale[2]])\n",
    "\n",
    "case21_size = (215, 251, 191)\n",
    "case21_scale = np.array([case21_size[0] / DeepReg_rescale[0], \n",
    "                         case21_size[1] / DeepReg_rescale[1], \n",
    "                         case21_size[2] / DeepReg_rescale[2]])\n",
    "\n",
    "case23_size = (106, 147, 134)\n",
    "case23_scale = np.array([case23_size[0] / DeepReg_rescale[0], \n",
    "                         case23_size[1] / DeepReg_rescale[1], \n",
    "                         case23_size[2] / DeepReg_rescale[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_centroid(image):\n",
    "    \"\"\"\n",
    "    Extract centroid from nifti images with landmark spheres\n",
    "    which have integer values according to labels\n",
    "    Adapted from: https://gist.github.com/mattiaspaul/f4183f525b1cbc65e71ad23298d6436e\n",
    "\n",
    "    :param image:\n",
    "        - shape: (dim_1, dim_2, dim_3) or (batch, dim_1, dim_2, dim_3)\n",
    "        - tensor or numpy array\n",
    "\n",
    "    :return positions:\n",
    "        - numpy array of labels 1\n",
    "    \"\"\"\n",
    "    assert len(image.shape) == 3\n",
    "\n",
    "    x = np.linspace(0, image.shape[0] - 1, image.shape[0])\n",
    "    y = np.linspace(0, image.shape[1] - 1, image.shape[1])\n",
    "    z = np.linspace(0, image.shape[2] - 1, image.shape[2])\n",
    "    yv, xv, zv = np.meshgrid(y, x, z)\n",
    "    unique = np.unique(image)[1:]  # don't include 0\n",
    "    positions = np.zeros((len(unique), 3))\n",
    "    for i in range(len(unique)):\n",
    "        label = (image == unique[i]).astype('float32')\n",
    "        xc = np.sum(label * xv) / np.sum(label)\n",
    "        yc = np.sum(label * yv) / np.sum(label)\n",
    "        zc = np.sum(label * zv) / np.sum(label)\n",
    "        positions[i, 0] = xc\n",
    "        positions[i, 1] = yc\n",
    "        positions[i, 2] = zc\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mTRE(xyz_true, xyz_predict):\n",
    "    assert xyz_true.shape == xyz_predict.shape\n",
    "    TRE = np.sqrt(np.sum(np.power(xyz_true - xyz_predict, 2), axis=1))\n",
    "    mTRE = np.mean(TRE)\n",
    "    return mTRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_TREs(pred_dir, pair_number, num_labels, affine, scale):\n",
    "    TREs = np.zeros(num_labels)\n",
    "    for i in range(num_labels):\n",
    "        label = nib.load(pred_dir + f\"pair_{pair_number}/label_{i}/fixed_label.nii.gz\")\n",
    "        pred_label = nib.load(pred_dir + f\"pair_{pair_number}/label_{i}/pred_fixed_label.nii.gz\")\n",
    "\n",
    "        label_np = label.get_fdata()\n",
    "        pred_label_np = pred_label.get_fdata()\n",
    "        \n",
    "        label_point = nib.affines.apply_affine(affine, extract_centroid(np.round(label_np))*scale)\n",
    "        pred_point = nib.affines.apply_affine(affine, extract_centroid(np.round(pred_label_np))*scale)\n",
    "        \n",
    "        TREs[i] = calculate_mTRE(label_point, pred_point)\n",
    "        \n",
    "    return TREs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calulating the mTRE for the 3 test cases for the Deep-Learning Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path to the prediction data\n",
    "prediction_dir = \"logs/91_final_test/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.99592999, 4.7669891 , 4.70059672, 5.15337782, 4.73786057,\n",
       "       5.40849391, 3.02772649, 5.58445234, 7.1831767 , 5.56912614,\n",
       "       4.25947545, 6.84398992, 6.75084262, 9.19574115, 4.36709064])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case2_TREs = case_TREs(prediction_dir, 0, 15, case2_affine, case2_scale)\n",
    "case2_TREs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mTRE for case 2 was 5.502991303450743\n"
     ]
    }
   ],
   "source": [
    "case2_mTRE = np.mean(case2_TREs)\n",
    "print(f\"The mTRE for case 2 was {case2_mTRE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.47045722, 3.97960624, 5.02442724, 3.82973097, 4.88126274,\n",
       "       4.72840392, 4.41295867, 5.18989909, 5.09077191, 3.45221441,\n",
       "       5.10201935, 4.50546756, 3.7981509 , 4.03465234, 4.06756056,\n",
       "       3.96497586])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case21_TREs = case_TREs(prediction_dir, 1, 16, case21_affine, case21_scale)\n",
    "case21_TREs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mTRE for case 21 was 4.53328493684857\n"
     ]
    }
   ],
   "source": [
    "case21_mTRE = np.mean(case21_TREs)\n",
    "print(f\"The mTRE for case 21 was {case21_mTRE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.42956974, 6.88552306, 8.1353113 , 6.41557738, 7.54661464,\n",
       "       8.21287229, 6.65678675, 8.3064462 , 8.11085698, 7.89990213,\n",
       "       5.21412917, 5.92343757, 5.29677218, 5.93879175, 8.2935333 ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case23_TREs = case_TREs(prediction_dir, 2, 15, case23_affine, case23_scale)\n",
    "case23_TREs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mTRE for case 23 was 7.017741627767024\n"
     ]
    }
   ],
   "source": [
    "case23_mTRE = np.mean(case23_TREs)\n",
    "print(f\"The mTRE for case 23 was {case23_mTRE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + SCC Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mTREs for CNN + SSC (rigid only...non-rigid was just as bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSC_affine_2 = np.array([[0.98227, 0.158062, 0.0692554, 4.02553e-07], \n",
    "                         [-0.19717, 0.742934, 0.0995561, 3.75881e-07],\n",
    "                         [-0.0975693,  -0.0915535, 0.97393, 4.33928e-07],\n",
    "                         [24.5656, 11.6949, -3.29517, 0.999908]]).T\n",
    "\n",
    "SSC_affine_21 = np.array([[0.999525, -0.00835235, 0.0296643, 0],\n",
    "                        [0.00760699, 0.999655, 0.0251491, 0],\n",
    "                        [-0.0298639, -0.0249113, 0.999244, 0],\n",
    "                        [1.24686, 1.07985, -1.03928, 1]]).T\n",
    "\n",
    "SSC_affine_23 = np.array([[0.998656, 0.0435814, 0.0280372, 0],\n",
    "                         [-0.0420885, 0.99777, -0.0518019, 0],\n",
    "                         [-0.0302323, 0.0505523, 0.998264, 0],\n",
    "                         [16.8089, -15.209, 17.1418, 1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_TREs_SSC(pred_dir, pair_number, num_labels, affine, SSC_affine, scale):\n",
    "    TREs = np.zeros(num_labels)\n",
    "    for i in range(num_labels):\n",
    "        label = nib.load(pred_dir + f\"pair_{pair_number}/label_{i}/fixed_label.nii.gz\")\n",
    "        pred_label = nib.load(pred_dir + f\"pair_{pair_number}/label_{i}/pred_fixed_label.nii.gz\")\n",
    "\n",
    "        label_np = label.get_fdata()\n",
    "        pred_label_np = pred_label.get_fdata()\n",
    "        \n",
    "        transformed_pred =  nib.affines.apply_affine(SSC_affine, extract_centroid(np.round(pred_label_np)))\n",
    "        \n",
    "        label_point = nib.affines.apply_affine(affine, extract_centroid(np.round(label_np))*scale)\n",
    "        pred_point = nib.affines.apply_affine(affine, transformed_pred*scale)\n",
    "        \n",
    "        TREs[i] = calculate_mTRE(label_point, pred_point)\n",
    "        \n",
    "    return TREs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path to the prediction data\n",
    "prediction_dir = \"logs/91_final_test/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.89919763,  9.8596831 ,  7.00554537,  6.85536062,  9.31029165,\n",
       "       11.71223314,  8.48062598,  8.93501441, 12.50851004, 11.91194414,\n",
       "        8.19810729,  9.4278252 , 11.58480622, 13.08085049,  6.82395628])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case2_TREs = case_TREs_SSC(prediction_dir, 0, 15, case2_affine, SSC_affine_2, case2_scale)\n",
    "case2_TREs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mTRE for case 2 was 9.506263436275505\n"
     ]
    }
   ],
   "source": [
    "case2_mTRE = np.mean(case2_TREs)\n",
    "print(f\"The mTRE for case 2 was {case2_mTRE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.40616255, 5.88861126, 6.73674602, 5.60125225, 6.48628728,\n",
       "       7.05890398, 7.06025771, 8.22671691, 7.34821473, 5.5905973 ,\n",
       "       6.84385844, 7.6735398 , 6.07672326, 6.38373297, 6.6709049 ,\n",
       "       6.39431789])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case21_TREs = case_TREs_SSC(prediction_dir, 1, 16, case21_affine, SSC_affine_21, case21_scale)\n",
    "case21_TREs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mTRE for case 21 was 6.715426702991234\n"
     ]
    }
   ],
   "source": [
    "case21_mTRE = np.mean(case21_TREs)\n",
    "print(f\"The mTRE for case 21 was {case21_mTRE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.66230843, 17.00998231, 18.73673049, 16.30623592, 17.78318241,\n",
       "       19.03787712, 16.82952526, 18.17905463, 18.74084351, 17.22146913,\n",
       "       13.56712936, 15.08025951, 14.65098937, 14.79147594, 18.82502464])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case23_TREs = case_TREs_SSC(prediction_dir, 2, 15, case23_affine, SSC_affine_23, case23_scale)\n",
    "case23_TREs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mTRE for case 23 was 16.89480586952979\n"
     ]
    }
   ],
   "source": [
    "case23_mTRE = np.mean(case23_TREs)\n",
    "print(f\"The mTRE for case 23 was {case23_mTRE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check: moving and fixed images (unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_SSC_affine_2 = np.array([[0.991165, 0.0244466, -0.130365, 0],\n",
    "                                  [-0.00110314, 0.984353, 0.176204, 0],\n",
    "                                  [0.132633, -0.174503, 0.975683, 0],\n",
    "                                  [-31.7493, -20.5851, -20.3543, 1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_TREs_SSC_unscaled(pred_dir, pair_number, num_labels, affine, SSC_affine, scale):\n",
    "    TREs = np.zeros(num_labels)\n",
    "    for i in range(num_labels):\n",
    "        label = nib.load(pred_dir + f\"pair_{pair_number}/label_{i}/fixed_label.nii.gz\")\n",
    "        pred_label = nib.load(pred_dir + f\"pair_{pair_number}/label_{i}/moving_label.nii.gz\")\n",
    "\n",
    "        label_np = label.get_fdata()\n",
    "        pred_label_np = pred_label.get_fdata() \n",
    "        \n",
    "        transformed_pred =  nib.affines.apply_affine(SSC_affine, extract_centroid(np.round(pred_label_np))*scale)\n",
    "        \n",
    "        label_point = nib.affines.apply_affine(affine, extract_centroid(np.round(label_np))*scale)\n",
    "        pred_point = nib.affines.apply_affine(affine, transformed_pred)\n",
    "        \n",
    "        TREs[i] = calculate_mTRE(label_point, pred_point)\n",
    "        \n",
    "    return TREs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path to the prediction data\n",
    "prediction_dir = \"logs/91_final_test/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.93468575, 22.79844001, 23.43421962, 23.0585836 , 23.63410866,\n",
       "       24.40299644, 21.92541149, 24.07677824, 25.79637311, 24.8816825 ,\n",
       "       22.33319162, 23.11547139, 24.61418481, 23.73617618, 22.96654215])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case2_TREs = case_TREs_SSC_unscaled(prediction_dir, 0, 15, case2_affine, unscaled_SSC_affine_2, case2_scale)\n",
    "case2_TREs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mTRE for case 2 was 23.5139230384455\n"
     ]
    }
   ],
   "source": [
    "case2_mTRE = np.mean(case2_TREs)\n",
    "print(f\"The mTRE for case 2 was {case2_mTRE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fails the sanity check and something is clearly seems wrong then with how we are testing with CNN+SCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing just moving and fixed (CNN scaled to 128x128x128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path to the prediction data\n",
    "prediction_dir = \"logs/91_final_test/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_affine_SSC_1 = np.array([[0.970629, 0.123898, 0.0611337, 4.38563e-06], \n",
    "                          [-0.187429, 0.76746, 0.160733, 3.77978e-06], \n",
    "                          [-0.164659, 0.0286062, 1.00569, 4.14213e-06], \n",
    "                          [35.0873, 6.22194, -9.00875, 0.999164]]).T\n",
    "\n",
    "test_affine_SSC_2 = np.array([[0.454008, 0.116395, 0.181164, 1.03077e-06],\n",
    "                              [-0.18823, 0.51896, -0.371127, 1.94371e-06],\n",
    "                              [-0.0139738, 0.805056, 1.52682, 1.32621e-06],\n",
    "                              [31.9663, 2.82907, 33.3063, 0.999684]]).T\n",
    "\n",
    "test_affine_SSC_3 = np.array([[0.840965, -0.516923, -0.606431, 1.46757e-06],\n",
    "                              [-0.067257, 0.0511995, -0.291972, 1.07902e-06],\n",
    "                              [-0.201934, 0.657801, 0.977594, 1.70895e-07],\n",
    "                              [4.65295, 78.8709, 78.4798, 0.999825]]).T\n",
    "\n",
    "\n",
    "test_affine_SSC_4 = np.array([[0.998762, -0.00312604, 0.0496527, 0],\n",
    "                              [0.00306486, 0.999994, 0.00130417, 0],\n",
    "                              [-0.0496564, -0.00115036, 0.998766, 0],\n",
    "                              [17.9524, 0.319942, 14.8488, 1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_TREs_SSC__(pred_dir, pair_number, num_labels, affine, SSC_affine, scale):\n",
    "    TREs = np.zeros(num_labels)\n",
    "    for i in range(num_labels):\n",
    "        label = nib.load(pred_dir + f\"pair_{pair_number}/label_{i}/fixed_label.nii.gz\")\n",
    "        pred_label = nib.load(pred_dir + f\"pair_{pair_number}/label_{i}/moving_label.nii.gz\")\n",
    "\n",
    "        label_np = label.get_fdata()\n",
    "        pred_label_np = pred_label.get_fdata()\n",
    "        \n",
    "        transformed_pred =  nib.affines.apply_affine(SSC_affine, extract_centroid(np.round(pred_label_np)))\n",
    "        \n",
    "        label_point = nib.affines.apply_affine(affine, extract_centroid(np.round(label_np))*scale)\n",
    "        pred_point = nib.affines.apply_affine(affine, transformed_pred*scale)\n",
    "        \n",
    "        TREs[i] = calculate_mTRE(label_point, pred_point)\n",
    "        \n",
    "    return TREs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.02437875,  9.50592548,  7.63118018,  7.92777259,  9.52471048,\n",
       "       10.61070698,  9.18837346,  8.99925713, 10.24778625, 11.19551575,\n",
       "        8.79173582, 10.3678349 , 10.05218003, 16.41707428,  7.24569682])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case2_TREs = case_TREs_SSC__(prediction_dir, 0, 15, case2_affine, test_affine_SSC_1, case2_scale)\n",
    "case2_TREs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mTRE for case 2 was 9.715341926481422\n"
     ]
    }
   ],
   "source": [
    "case2_mTRE = np.mean(case2_TREs)\n",
    "print(f\"The mTRE for case 2 was {case2_mTRE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47.15037785, 26.8587612 , 29.03011669, 50.13070182, 20.44732741,\n",
       "       25.89887176, 18.86033692, 26.04985593, 37.34920221, 21.7135323 ,\n",
       "       24.67254931, 38.84744031, 36.18452904, 27.9711532 , 52.92692419])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case2_TREs = case_TREs_SSC__(prediction_dir, 0, 15, case2_affine, test_affine_SSC_2, case2_scale)\n",
    "case2_TREs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mTRE for case 2 was 32.27277867452295\n"
     ]
    }
   ],
   "source": [
    "case2_mTRE = np.mean(case2_TREs)\n",
    "print(f\"The mTRE for case 2 was {case2_mTRE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42.02724955, 17.2086385 , 20.22055004, 47.09045049, 17.20753374,\n",
       "       18.34937172, 17.2592487 , 22.92149937, 31.99936864, 25.17083639,\n",
       "       15.87855536, 36.59913957, 29.20965219, 39.01910603, 53.18504964])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case2_TREs = case_TREs_SSC__(prediction_dir, 0, 15, case2_affine, test_affine_SSC_3, case2_scale)\n",
    "case2_TREs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mTRE for case 2 was 28.88974999421106\n"
     ]
    }
   ],
   "source": [
    "case2_mTRE = np.mean(case2_TREs)\n",
    "print(f\"The mTRE for case 2 was {case2_mTRE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.01158059, 12.51018908, 12.57980168, 13.91442032, 11.9355573 ,\n",
       "       11.74945179, 11.39724055, 12.7841462 , 13.32033277,  9.75518109,\n",
       "       12.67367006, 15.45767684, 13.81351563, 17.12468246, 13.14934387])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case2_TREs = case_TREs_SSC__(prediction_dir, 0, 15, case2_affine, test_affine_SSC_4, case2_scale)\n",
    "case2_TREs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mTRE for case 2 was 13.07845268207958\n"
     ]
    }
   ],
   "source": [
    "case2_mTRE = np.mean(case2_TREs)\n",
    "print(f\"The mTRE for case 2 was {case2_mTRE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
